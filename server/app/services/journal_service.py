import json
from datetime import date as date_type
from uuid import UUID

from redis.asyncio import Redis
from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import joinedload

from app.models import Journal, User, Repository
from app.schemas.journal import JournalCreate, JournalUpdate, JournalResponse, JournalStatusResponse
from app.services.gemini_service import GeminiService
from app.services.github_service import fetch_commits, GithubNoCommitsError

from loguru import logger

class JournalService:
    def __init__(self, db: AsyncSession, redis: Redis = None):
        self.db = db
        self.redis = redis
        self.gemini_service = GeminiService()
    
    async def check_daily_status(
        self,
        user: User,
        date: date_type
    ) -> JournalStatusResponse:
        """Ïò§Îäò ÏùºÏßÄ ÏÉùÏÑ± ÏÉÅÌÉú ÌôïÏù∏"""
        # 1. Í∏∞Ï°¥ ÏùºÏßÄ Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏
        stmt = select(Journal).where(
            Journal.user_id == user.id,
            Journal.repository_id == user.selected_repo_id,
            Journal.date == date
        )
        result = await self.db.execute(stmt)
        has_journal = result.scalar_one_or_none() is not None

        # 2. Ïª§Î∞ã Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏
        has_commits = False
        if user.selected_repo_id:
            # Repository Ï†ïÎ≥¥ Ï°∞Ìöå
            repo_stmt = select(Repository).where(Repository.id == user.selected_repo_id)
            repo_result = await self.db.execute(repo_stmt)
            repo = repo_result.scalar_one_or_none()

            if repo:
                try:
                    # Ïª§Î∞ã Ï°∞Ìöå ÏãúÎèÑ (ÏóêÎü¨ Î∞úÏÉù Ïãú Ïª§Î∞ã ÏóÜÏùåÏúºÎ°ú Ï≤òÎ¶¨)
                    await fetch_commits(
                        repo_name=repo.repo_name,
                        target_date=date,
                        access_token=user.decrypted_access_token
                    )
                    has_commits = True
                except GithubNoCommitsError:
                    has_commits = False
                except Exception as e:
                    logger.warning(f"Ïª§Î∞ã ÌôïÏù∏ Ï§ë ÏóêÎü¨: {e}")
                    has_commits = False

        return JournalStatusResponse(
            date=date,
            has_journal=has_journal,
            has_commits=has_commits,
            can_generate=has_commits # (ÏÑ†ÌÉùÏÇ¨Ìï≠: and not has_journal Ï°∞Í±¥ÏùÑ ÎÑ£ÏùÑ ÏàòÎèÑ ÏûàÏùå)
        )
        
    async def create_daily_journal(
        self,
        user: User,
        date: date_type,
        overwrite: bool = True
    ) -> Journal:
        """
        1. Ï†ÄÏû•ÏÜå Ï†ïÎ≥¥ ÌôïÏù∏
        2. GitHub Ïª§Î∞ã ÏàòÏßë
        3. Gemini AI Î∂ÑÏÑù
        4. DB Upsert (Ìä∏ÎûúÏû≠ÏÖò)
        """
        logger.info("‚úÖ [JournalService] ÍπÉÌóàÎ∏å Ïª§Î∞ã ÏùºÏßÄ ÏÉùÏÑ± Ìï®Ïàò ÏßÑÏûÖ!!")
        
        # 1. ÏÑ†ÌÉùÎêú Ï†ÄÏû•ÏÜå ÌôïÏù∏ (Eager Loading ÌïÑÏöî)
        if not user.selected_repo_id:
             raise ValueError("No repository selected")
         
        # User Í∞ùÏ≤¥Ïóê repositoriesÍ∞Ä Î°úÎìúÎêòÏßÄ ÏïäÏïòÏùÑ Ïàò ÏûàÏúºÎØÄÎ°ú DBÏóêÏÑú Ï°∞Ìöå
        stmt = select(Repository).where(Repository.id == user.selected_repo_id)
        try:
            result = await self.db.execute(stmt)
            repo = result.scalar_one_or_none()
            
            if not repo:
                raise ValueError("Repository not found")
            
            # 2. Ïª§Î∞ã ÏàòÏßë
            commits = await fetch_commits(
                repo_name=repo.repo_name,
                target_date=date,
                access_token=user.decrypted_access_token
            )
            
            # 3. AI Î∂ÑÏÑù
            ai_data = await self.gemini_service.generate_journal(commits, date)
            
            # ÌÜµÍ≥Ñ Ï∂îÏ∂ú (GitHub Ïª§Î∞ã Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Í≥ÑÏÇ∞)
            stats = self._calculate_stats(commits)
            logger.info(f"ÌÜµÍ≥Ñ Ï∂îÏ∂ú: {stats}")
            journal_data = JournalCreate(
                user_id=user.id,
                repository_id=repo.id,
                date=date,
                raw_commits=commits,  # ÎîîÎ≤ÑÍπÖÏö© Ï†ÄÏû•
                **ai_data,            # summary, main_tasks, learned_things
                **stats               # commit_count, files_changed Îì±
            )
            
            # 4. DB Ï†ÄÏû• (Upsert)
            # upsert Î°úÏßÅ ÏàòÌñâ (add, update Îì±)
            journal = await self._upsert_journal(journal_data, overwrite)
            
            # ‚úÖ ÌïµÏã¨: Î™®Îì† ÏûëÏóÖÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÎÅùÎÇòÎ©¥ Ïó¨Í∏∞ÏÑú Ïª§Î∞ã
            await self.db.commit()
            
            # Ïª§Î∞ã ÌõÑ Í∞ùÏ≤¥ Î¶¨ÌîÑÎ†àÏãú (DBÏóêÏÑú ÏµúÏã† Îç∞Ïù¥ÌÑ∞ Î°úÎìú)
            await self.db.refresh(journal)
            return journal
        
        except Exception as e:
            # ÏóêÎü¨ Î∞úÏÉù Ïãú Î°§Î∞±ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞ Ï†ïÌï©ÏÑ± Ïú†ÏßÄ
            await self.db.rollback()
            raise e
    
    def _calculate_stats(self, commits: list[dict]) -> dict:
        """Ïª§Î∞ã Î¶¨Ïä§Ìä∏ÏóêÏÑú ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï∂îÏ∂ú (Optimized Structure ÎåÄÏùë)"""
        files_changed = 0
        lines_added = 0
        lines_deleted = 0
        
        for commit in commits:
            files = commit.get("files", [])
            files_changed += len(files)
            for f in files:
                lines_added += f.get("additions", 0)
                lines_deleted += f.get("deletions", 0)
                
        return {
            "commit_count": len(commits),
            "files_changed": files_changed,
            "lines_added": lines_added,
            "lines_deleted": lines_deleted,
        }
        
    async def _upsert_journal(self, data: JournalCreate, overwrite: bool) -> Journal:
        logger.info("[JournalService] ÏùºÏßÄ ÏÉùÏÑ± Î∞è ÎçÆÏñ¥ÏîåÍ∏∞ commitÌï®Ïàò ÏßÑÏûÖ")
        
        # Í∏∞Ï°¥ ÏùºÏßÄ Ï°∞Ìöå
        stmt = select(Journal).where(
            Journal.user_id == data.user_id,
            Journal.repository_id == data.repository_id,
            Journal.date == data.date
        )
        try:
            result = await self.db.execute(stmt)
            existing = result.scalar_one_or_none()
            
            if existing:
                if not overwrite:
                    raise ValueError("Journal already exists")
                
                # ÏóÖÎç∞Ïù¥Ìä∏
                for key, value in data.model_dump().items():
                    setattr(existing, key, value)
                    
                return existing
                
            # Ïã†Í∑ú ÏÉùÏÑ±
            new_journal = Journal(**data.model_dump())
            self.db.add(new_journal)
            return new_journal
        
        except Exception as e:
            await self.db.rollback()
            raise e
    
    async def get_journals(
        self,
        user_id: UUID,
        repository_id: UUID,
        page: int = 1,
        size: int = 10,
        start_date: date_type | None = None,
        end_date: date_type | None = None,
    ) -> tuple[list[Journal], int]:
        try:
            """ÏùºÏßÄ Î™©Î°ù Ï°∞Ìöå (ÌéòÏù¥ÏßÄÎÑ§Ïù¥ÏÖò)"""
            conditions = [Journal.user_id == user_id]
            # ÎÇ†Ïßú ÌïÑÌÑ∞ÎßÅ
            if start_date:
                conditions.append(Journal.date >= start_date)
            if end_date:
                conditions.append(Journal.date <= end_date)
                
            if repository_id:
                conditions.append(Journal.repository_id == repository_id)    
            
            count_stmt = select(func.count()).select_from(Journal).where(*conditions)
            total = (await self.db.execute(count_stmt)).scalar() or 0
            
            stmt = (
                select(Journal)
                .options(joinedload(Journal.repository)) # N+1Î∞©ÏßÄ
                .where(*conditions)
                .order_by(Journal.date.desc())
                .offset((page-1) * size)
                .limit(size)
            )
            result = await self.db.execute(stmt)
            items = result.scalars().all()
            
            return items, total
        
        except Exception as e:
            await self.db.rollback()
            raise e
        
    async def get_journal_detail(self, user_id: UUID, journal_id: UUID) -> dict | Journal | None:
        """
        ÏùºÏßÄ ÏÉÅÏÑ∏ Ï°∞Ìöå (Redis Caching Ï†ÅÏö©)
        - Cache Hit: dict Î∞òÌôò
        - Cache Miss: Journal(ORM) Î∞òÌôò (RouterÍ∞Ä Ï≤òÎ¶¨ Í∞ÄÎä•)
        """
        cache_key = f"journal:{user_id}:{journal_id}"
        
        # 1. Redis Ï∫êÏãú ÌôïÏù∏(Hit)
        if self.redis:
            try:
                cached_data = await self.redis.get(cache_key)
                if cached_data:
                    logger.info(f"‚ö°Cache Hit: {cache_key}")
                    return json.loads(cached_data) # dict Î∞òÌôò
            except Exception as e:
                logger.warning(f"Redis get error: {e}")
        
        # 2. DB Ï°∞Ìöå (Miss)
        stmt = select(Journal).where(
            Journal.id == journal_id,
            Journal.user_id == user_id
        )
        result = await self.db.execute(stmt)
        journal = result.scalar_one_or_none()
        
        # 3. Redis Ï†ÄÏû• (Set)
        if journal and self.redis:
            try:
                # pydantic Î™®Îç∏Î°ú Î≥ÄÌôòÌïòÏó¨ JSON ÏßÅÎ†¨Ìôî
                # (ORMÍ∞ùÏ≤¥ -> Pydantic -> JSON)
                journal_data = JournalResponse.model_validate(journal).model_dump_json()
                
                await self.redis.setex(
                    cache_key,
                    86400, # TTL : 24H
                    journal_data
                )
                logger.info(f"üíæ Cache Set: {cache_key}")
            except Exception as e:
                logger.warning(f"Redis set error: {e}")
        
        return journal
    
    async def _get_journal_orm(self, user_id: UUID, journal_id: UUID) -> Journal | None:
        """
        ÏàòÏ†ï/ÏÇ≠Ï†úÏö© ORM Í∞ùÏ≤¥ ÏßÅÏ†ë Ï°∞ÌöåÏö© Ìó¨ÌçºÎ©îÏÑúÎìú (Ï∫êÏãú ÎØ∏ÏÇ¨Ïö©)
        „Ñ¥ ÏàòÏ†ï/ÏÇ≠Ï†úÎäî Îç∞Ïù¥ÌÑ∞ Ï†ïÌï©ÏÑ±Ïù¥ Ï§ëÏöîÌïòÍ≥† ORM Í∞ùÏ≤¥Í∞Ä ÌïÑÏöî
        """
        stmt = select(Journal).where(
            Journal.id == journal_id,
            Journal.user_id == user_id
        )
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def update_journal(
        self,
        user_id: UUID,
        journal_id: UUID,
        data: JournalUpdate
    ) -> Journal:
        try:
            """ÏùºÏßÄ ÏàòÏ†ï"""
            journal = await self._get_journal_orm(user_id, journal_id)
            if not journal:
                raise ValueError("journal not found")
            
            update_date = data.model_dump(exclude_unset=True)
            for key, value in update_date.items():
                setattr(journal, key, value)
            
        
            self.db.add(journal)
            await self.db.commit()
            await self.db.refresh(journal)
            
            if self.redis:
                await self.redis.delete(f"journal:{user_id}:{journal_id}")
                logger.info("‚ùå Cache Invalidate")
            return journal
        
        except Exception as e:
            await self.db.rollback()
            raise e
        
    async def delete_journal(self, user_id: UUID, journal_id: UUID) -> None:
        """ÏùºÏßÄ ÏÇ≠Ï†ú"""
        try:
            journal = await self._get_journal_orm(user_id, journal_id)
            
            if not journal:
                raise ValueError("Journal not found")
        
            await self.db.delete(journal)
            await self.db.commit()
            
            if self.redis:
                await self.redis.delete(f"journal:{user_id}:{journal_id}")
                logger.info("‚ùå Cache Invalidate")
                
        except Exception as e:
            await self.db.rollback()
            raise e