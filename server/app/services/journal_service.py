import json
from datetime import date as date_type
from uuid import UUID

from redis.asyncio import Redis
from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import joinedload

from app.models import Journal, User, Repository
from app.schemas.journal import JournalCreate, JournalUpdate, JournalResponse
from app.services.gemini_service import GeminiService
from app.services.github_service import fetch_commits

from loguru import logger

class JournalService:
    def __init__(self, db: AsyncSession, redis: Redis = None):
        self.db = db
        self.redis = redis
        self.gemini_service = GeminiService()
        
    async def create_daily_journal(
        self,
        user: User,
        date: date_type,
        overwrite: bool = True
    ) -> Journal:
        """
        1. Ï†ÄÏû•ÏÜå Ï†ïÎ≥¥ ÌôïÏù∏
        2. GitHub Ïª§Î∞ã ÏàòÏßë
        3. Gemini AI Î∂ÑÏÑù
        4. DB Upsert (Ìä∏ÎûúÏû≠ÏÖò)
        """
        logger.info("‚úÖ [JournalService] ÍπÉÌóàÎ∏å Ïª§Î∞ã ÏùºÏßÄ ÏÉùÏÑ± Ìï®Ïàò ÏßÑÏûÖ!!")
        
        # 1. ÏÑ†ÌÉùÎêú Ï†ÄÏû•ÏÜå ÌôïÏù∏ (Eager Loading ÌïÑÏöî)
        if not user.selected_repo_id:
             raise ValueError("No repository selected")
         
        # User Í∞ùÏ≤¥Ïóê repositoriesÍ∞Ä Î°úÎìúÎêòÏßÄ ÏïäÏïòÏùÑ Ïàò ÏûàÏúºÎØÄÎ°ú DBÏóêÏÑú Ï°∞Ìöå
        stmt = select(Repository).where(Repository.id == user.selected_repo_id)
        result = await self.db.execute(stmt)
        repo = result.scalar_one_or_none()
        
        logger.debug(f"üì∂Î¶¨Ìè¨ÏßÄÌÜ†Î¶¨ Ïú†Î¨¥ ÌåêÎã® =====> {repo}")
        
        if not repo:
             raise ValueError("Repository not found")
         
        # 2. Ïª§Î∞ã ÏàòÏßë
        commits = await fetch_commits(
            repo_name=repo.repo_name,
            target_date=date,
            access_token=user.decrypted_access_token
        )
        
        # 3. AI Î∂ÑÏÑù
        ai_data = await self.gemini_service.generate_journal(commits, date)
        
        # ÌÜµÍ≥Ñ Ï∂îÏ∂ú (GitHub Ïª§Î∞ã Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Í≥ÑÏÇ∞)
        stats = self._calculate_stats(commits)
        
        journal_data = JournalCreate(
            user_id=user.id,
            repository_id=repo.id,
            date=date,
            raw_commits=commits,  # ÎîîÎ≤ÑÍπÖÏö© Ï†ÄÏû•
            **ai_data,            # summary, main_tasks, learned_things
            **stats               # commit_count, files_changed Îì±
        )
        # 4. DB Ï†ÄÏû• (Upsert)
        try:
            # upsert Î°úÏßÅ ÏàòÌñâ (add, update Îì±)
            journal = await self._upsert_journal(journal_data, overwrite)
            # ‚úÖ ÌïµÏã¨: Î™®Îì† ÏûëÏóÖÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÎÅùÎÇòÎ©¥ Ïó¨Í∏∞ÏÑú Ïª§Î∞ã
            await self.db.commit()
            # Ïª§Î∞ã ÌõÑ Í∞ùÏ≤¥ Î¶¨ÌîÑÎ†àÏãú (DBÏóêÏÑú ÏµúÏã† Îç∞Ïù¥ÌÑ∞ Î°úÎìú)
            await self.db.refresh(journal)
            return journal
        
        except Exception as e:
            # ÏóêÎü¨ Î∞úÏÉù Ïãú Î°§Î∞±ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞ Ï†ïÌï©ÏÑ± Ïú†ÏßÄ
            await self.db.rollback()
            raise e
    
    def _calculate_stats(self, commits: list[dict]) -> dict:
        """Ïª§Î∞ã Î¶¨Ïä§Ìä∏ÏóêÏÑú ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï∂îÏ∂ú"""
        return {
            "commit_count": len(commits),
            "files_changed": sum(c.get("files_changed", 0) for c in commits), # GitHub API ÏùëÎãµ Íµ¨Ï°∞ ÌôïÏù∏ ÌïÑÏöî
            "lines_added": sum(c.get("stats", {}).get("additions", 0) for c in commits),
            "lines_deleted": sum(c.get("stats", {}).get("deletions", 0) for c in commits),
        }
        
    async def _upsert_journal(self, data: JournalCreate, overwrite: bool) -> Journal:
        logger.info("[JournalService] ÏùºÏßÄ ÏÉùÏÑ± Î∞è ÎçÆÏñ¥ÏîåÍ∏∞ commitÌï®Ïàò ÏßÑÏûÖ")
        
        # Í∏∞Ï°¥ ÏùºÏßÄ Ï°∞Ìöå
        stmt = select(Journal).where(
            Journal.user_id == data.user_id,
            Journal.repository_id == data.repository_id,
            Journal.date == data.date
        )
        
        result = await self.db.execute(stmt)
        existing = result.scalar_one_or_none()
        
        if existing:
            if not overwrite:
                raise ValueError("Journal already exists")
            
            # ÏóÖÎç∞Ïù¥Ìä∏
            for key, value in data.model_dump().items():
                setattr(existing, key, value)
                
            return existing
            
        # Ïã†Í∑ú ÏÉùÏÑ±
        new_journal = Journal(**data.model_dump())
        self.db.add(new_journal)
        return new_journal
    
    
    async def get_journals(
        self,
        user_id: UUID,
        page: int = 1,
        size: int = 10,
        start_date: date_type | None = None,
        end_date: date_type | None = None
    ) -> tuple[list[Journal], int]:
        
        """ÏùºÏßÄ Î™©Î°ù Ï°∞Ìöå (ÌéòÏù¥ÏßÄÎÑ§Ïù¥ÏÖò)"""
        conditions = [Journal.user_id == user_id]
        # ÎÇ†Ïßú ÌïÑÌÑ∞ÎßÅ
        if start_date:
            conditions.append(Journal.date >= start_date)
        if end_date:
            conditions.append(Journal.date <= end_date)
            
        count_stmt = select(func.count()).select_from(Journal).where(*conditions)
        total = (await self.db.execute(count_stmt)).scalar() or 0
        
        stmt = (
            select(Journal)
            .options(joinedload(Journal.repository)) # N+1Î∞©ÏßÄ
            .where(*conditions)
            .order_by(Journal.date.desc())
            .offset((page-1) * size)
            .limit(size)
        )
        result = await self.db.execute(stmt)
        items = result.scalars().all()
        
        return items, total
        
    async def get_journal_detail(self, user_id: UUID, journal_id: UUID) -> dict | Journal | None:
        """
        ÏùºÏßÄ ÏÉÅÏÑ∏ Ï°∞Ìöå (Redis Caching Ï†ÅÏö©)
        - Cache Hit: dict Î∞òÌôò
        - Cache Miss: Journal(ORM) Î∞òÌôò (RouterÍ∞Ä Ï≤òÎ¶¨ Í∞ÄÎä•)
        """
        cache_key = f"journal:{user_id}:{journal_id}"
        
        # 1. Redis Ï∫êÏãú ÌôïÏù∏(Hit)
        if self.redis:
            try:
                cached_data = await self.redis.get(cache_key)
                if cached_data:
                    logger.info(f"‚ö°Cache Hit: {cache_key}")
                    return json.loads(cached_data) # dict Î∞òÌôò
            except Exception as e:
                logger.warning(f"Redis get error: {e}")
        
        # 2. DB Ï°∞Ìöå (Miss)
        stmt = select(Journal).where(
            Journal.id == journal_id,
            Journal.user_id == user_id
        )
        result = await self.db.execute(stmt)
        journal = result.scalar_one_or_none()
        
        # 3. Redis Ï†ÄÏû• (Set)
        if journal and self.redis:
            try:
                # pydantic Î™®Îç∏Î°ú Î≥ÄÌôòÌïòÏó¨ JSON ÏßÅÎ†¨Ìôî
                # (ORMÍ∞ùÏ≤¥ -> Pydantic -> JSON)
                journal_data = JournalResponse.model_validate(journal).model_dump_json()
                
                await self.redis.setex(
                    cache_key,
                    86400, # TTL : 24H
                    journal_data
                )
                logger.info(f"üíæ Cache Set: {cache_key}")
            except Exception as e:
                logger.warning(f"Redis set error: {e}")
        
        return journal
    
    async def _get_journal_orm(self, user_id: UUID, journal_id: UUID) -> Journal | None:
        """
        ÏàòÏ†ï/ÏÇ≠Ï†úÏö© ORM Í∞ùÏ≤¥ ÏßÅÏ†ë Ï°∞ÌöåÏö© Ìó¨ÌçºÎ©îÏÑúÎìú (Ï∫êÏãú ÎØ∏ÏÇ¨Ïö©)
        „Ñ¥ ÏàòÏ†ï/ÏÇ≠Ï†úÎäî Îç∞Ïù¥ÌÑ∞ Ï†ïÌï©ÏÑ±Ïù¥ Ï§ëÏöîÌïòÍ≥† ORM Í∞ùÏ≤¥Í∞Ä ÌïÑÏöî
        """
        stmt = select(Journal).where(
            Journal.id == journal_id,
            Journal.user_id == user_id
        )
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def update_journal(
        self,
        user_id: UUID,
        journal_id: UUID,
        data: JournalUpdate
    ) -> Journal:
        """ÏùºÏßÄ ÏàòÏ†ï"""
        journal = await self._get_journal_orm(user_id, journal_id)
        if not journal:
            raise ValueError("journal not found")
        
        update_date = data.model_dump(exclude_unset=True)
        for key, value in update_date.items():
            setattr(journal, key, value)
            
        try:
            self.db.add(journal)
            await self.db.commit()
            await self.db.refresh(journal)
            
            if self.redis:
                await self.redis.delete(f"journal:{user_id}:{journal_id}")
                
            return journal
        
        except Exception as e:
            await self.db.rollback()
            raise e
        
    async def delete_journal(self, user_id: UUID, journal_id: UUID) -> None:
        """ÏùºÏßÄ ÏÇ≠Ï†ú"""
        journal = await self._get_journal_orm(user_id, journal_id)
        
        if not journal:
            raise ValueError("Journal not found")
        
        try:
            await self.db.delete(journal)
            await self.db.commit()
            
            if self.redis:
                await self.redis.delete(f"journal:{user_id}:{journal_id}")
                
        except Exception as e:
            await self.db.rollback()
            raise e